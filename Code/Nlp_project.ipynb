{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nlp_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiNnDAvIg6dw"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import requests"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJH2lIodF34l"
      },
      "source": [
        "- Create array of strings \\n seperated\n",
        "- code need to be updated (not optimised one sequential things neeed to implement nparray with broadcast)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__ZST7FqMS4i"
      },
      "source": [
        "a_file = \"/content/drive/MyDrive/Classification/CodeMixcorpora/test.txt\"\n",
        "response = open(a_file).read()\n",
        "response = response.lower()\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-9tWXw5Oba9"
      },
      "source": [
        "list_of_lists = []\n",
        "\n",
        "for line in response:\n",
        "  #stripped_line = line.strip()\n",
        "  #line_list = stripped_line.split()\n",
        "\n",
        "  list_of_lists.append(line)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM3vxsm8Jkp0",
        "outputId": "8dd3206c-7f1c-4510-85b2-2bbb2645cb74"
      },
      "source": [
        "len(list_of_lists)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8835222"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "6FapfklYJ0mE",
        "outputId": "100c4fd5-8308-4fdc-c82c-5c581155b969"
      },
      "source": [
        "response[:1500]\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\" <unk> bharat me ajaad he , lekin china se tibbat tabhi ajaad hoga jab <unk> fight karenge , jo mujhe ni lagta , kyunki wo bharat ko hi apna desh manane lage he , active movement ni he unka \"\\nindian army kashmiri logo ko nahi atankvadiyo ko mar rahi hai\\nabbe keyo fek raha hai andhe news dalal\\nmather chooo dukan laga ke baitha rahta hai . digital indiaa . enn sab ko ban . karna cha he ye\\njab modiji ne mudda utha hi diya ha to isko international community ke <unk> bhi jordar <unk> se uthaye ki pak baluch ke sath kaisa\\nab kasmir pe rone wale apni army ko kuchh kahenge hum yha <unk> gun use ker rhe to badi jal rhi waha to real gun use ho rhi\\njaldi sena vejo ............ ab wo time ageya ... now baluchistan want freedom\\nvote to maine es bar bhi modi jee ko hi diya tha agee bhi bjp ko hi jayega but kuch sahi to ho jispe bitta hai wahi samjega na ankush bahi ko dekhiye gali deker ser samaj rahe hai\\nmr modi you are on right path\\nab pakistan ka namo nishan mitne ka din nazdeek aa gya hai i salute modi g\\npakistan ka ant hone ka time aageya .\\npart time jop dene ka ead dalne walo ki ma ki aakh\\n\" jese kashmiri mar rhe hai same . wha wo mar rhe hai ... waw . kya politics me aam admi marta hi rhega . \"\\nagar ye kisi bjp ke state mai hota to sabhi party pohoch jati waha pr bhai ye modi ka kaam nhi state government kiya jhak mr rahi hai hr chiz mai modi ka naam kyu desh subse <unk> pm hai modi\\nmodi kuc karo garib par julm nahi hona cahiy\\n\" ab aap judiye hamare sath digital india me or ghar be'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "np_QLJyKNOne",
        "outputId": "9636125e-4d1c-4f8d-b034-fa4679a44f7e"
      },
      "source": [
        "print(type(response))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "BwR19G9sJ1bP",
        "outputId": "13e1cdbc-65dd-443c-e5ce-048f96c10fbb"
      },
      "source": [
        "data = response.split('\\n')\n",
        "data[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\" <unk> bharat me ajaad he , lekin china se tibbat tabhi ajaad hoga jab <unk> fight karenge , jo mujhe ni lagta , kyunki wo bharat ko hi apna desh manane lage he , active movement ni he unka \"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ZZXbucTWJ7cf",
        "outputId": "62fdc91d-1799-4bcb-c066-829b0e240d39"
      },
      "source": [
        "data = data[253:]\n",
        "data[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"mithai kiyo di pakistani ranger 's ko thora sa chitta de dete punjab sarkar se lekar\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix4juT3-J-t4",
        "outputId": "8d0da84a-ff35-4fc7-8135-73f4b2d2a1b3"
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/', 'c', 'o', 'n', 't', 'e', 'n', 't', '/', 'd', 'r', 'i', 'v', 'e', '/', 'M', 'y', 'D', 'r', 'i', 'v', 'e', '/', 'C', 'l', 'a', 's', 's', 'i', 'f', 'i', 'c', 'a', 't', 'i', 'o', 'n', '/', 'C', 'o', 'd', 'e', 'M', 'i', 'x', 'c', 'o', 'r', 'p', 'o', 'r', 'a', '/', 't', 'e', 's', 't', '.', 't', 'x', 't']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvhG0iwPGS8F"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1xE1fXgGRup"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qYLp1UHYKCNW",
        "outputId": "79f5ca80-a729-4945-9949-a1993e96d7e4"
      },
      "source": [
        "data = \" \".join(data)\n",
        "data[:2]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'mi'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI5wg3JPGQ2G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvB7dujSGUOq"
      },
      "source": [
        "- Simple cleaning and tokenisation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOG7CxGGKGpt",
        "outputId": "7513dfb4-df08-4ab1-9b77-93a58ada77d4"
      },
      "source": [
        "def clean_text(doc):\n",
        "  tokens = doc.split()\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  tokens = [w.translate(table) for w in tokens]\n",
        "  tokens = [word for word in tokens if word.isalpha()]\n",
        "  tokens = [word.lower() for word in tokens]\n",
        "  return tokens\n",
        "\n",
        "tokens = clean_text(data)\n",
        "print(tokens[:50])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['mithai', 'kiyo', 'di', 'pakistani', 'ranger', 's', 'ko', 'thora', 'sa', 'chitta', 'de', 'dete', 'punjab', 'sarkar', 'se', 'lekar', 'him', 'log', 'pyar', 'chahte', 'he', 'leken', 'pakestan', 'unk', 'chah', 'the', 'hai', 'hmare', 'desks', 'unk', 'mare', 'jate', 'he', 'ar', 'him', 'kochh', 'nhi', 'kr', 'pate', 'hai', 'ete', 'jar', 'krte', 'hai', 'ek', 'tarah', 'indian', 'army', 'ki', 'taraf']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eTXvh5BKMxU",
        "outputId": "5552b69f-4972-4693-ec11-a5acae6cb0d9"
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1638495"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpV0cdPqKU2m",
        "outputId": "424b4ff7-cd54-4362-9a06-a881d6be9830"
      },
      "source": [
        "length = 50 + 1\n",
        "lines = []\n",
        "\n",
        "for i in range(length, len(tokens)):\n",
        "  seq = tokens[i-length:i]\n",
        "  line = ' '.join(seq)\n",
        "  lines.append(line)\n",
        "  if i > 200000:\n",
        "    break\n",
        "\n",
        "print(len(lines))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "199951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52nV4LW4KYbJ"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qPqYyOsKdEw"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS1iloLLKgIo",
        "outputId": "738ade9c-29cf-4de6-dcf3-ddc04f5b3f66"
      },
      "source": [
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:, :-1], sequences[:,-1]\n",
        "X[0]\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3987,  3986,   161,   615, 20912,    85,     5,  3009,   532,\n",
              "       20911,   100,   368,   195,   225,    12,   735,   363,    64,\n",
              "         927,  1035,    27, 20910, 20909,     1,  3985,    16,     2,\n",
              "        1447, 20908,     1,   782,   542,    27,  1034,   363, 20906,\n",
              "          37,    81,  3984,     2, 20905,  4822,   361,     2,    48,\n",
              "         419,   121,   381,     4,   903])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bic17g0LKkCO"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhwtuVUhKnU9"
      },
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecF4jTuVKqkq",
        "outputId": "da213761-1191-4617-da76-41f8909e5520"
      },
      "source": [
        "seq_length = X.shape[1]\n",
        "seq_length"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rdZSiLFKu5X"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVYSYOUoKzGE"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8EQGqJ2MK22_",
        "outputId": "37dd54c0-00f8-42bd-c7a4-d486cb0371f9"
      },
      "source": [
        "model.fit(X, y, batch_size = 256, epochs = 100)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "189/782 [======>.......................] - ETA: 5:26 - loss: 7.8088 - accuracy: 0.0240"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-19-924e70a18025>\", line 1, in <module>\n",
            "    model.fit(X, y, batch_size = 256, epochs = 100)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 1100, in fit\n",
            "    tmp_logs = self.train_function(iterator)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 855, in _call\n",
            "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 2943, in __call__\n",
            "    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 1919, in _call_flat\n",
            "    ctx, args, cancellation_manager=cancellation_manager))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 560, in call\n",
            "    ctx=ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
            "    inputs, attrs, num_outputs)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 739, in getmodule\n",
            "    f = getabsfile(module)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 708, in getabsfile\n",
            "    _filename = getsourcefile(object) or getfile(object)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 685, in getsourcefile\n",
            "    all_bytecode_suffixes = importlib.machinery.DEBUG_BYTECODE_SUFFIXES[:]\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2nQTqjJGiIZ"
      },
      "source": [
        "- Peek any line from text to work on for text generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "5ezp1-34K5qy",
        "outputId": "c32d154a-d5f2-4f08-80cd-0db07182d7fd"
      },
      "source": [
        "seed_text=lines[12343]\n",
        "seed_text"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-40782a947fc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseed_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12343\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mseed_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'lines' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNVffkczGhOd"
      },
      "source": [
        "Generate Text sequence length according to requirement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxgMTkDbK9hT"
      },
      "source": [
        "def generate_text_seq(model, tokenizer, text_seq_length, seed_text, n_words):\n",
        "  text = []\n",
        "\n",
        "  for _ in range(n_words):\n",
        "    encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen = text_seq_length, truncating='pre')\n",
        "\n",
        "    y_predict = model.predict_classes(encoded)\n",
        "\n",
        "    predicted_word = ''\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == y_predict:\n",
        "        predicted_word = word\n",
        "        break\n",
        "    seed_text = seed_text + ' ' + predicted_word\n",
        "    text.append(predicted_word)\n",
        "  return ' '.join(text)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxycx0HcLAvo"
      },
      "source": [
        "generate_text_seq(model, tokenizer, seq_length, seed_text, 100)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1_qORQgLD-7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}