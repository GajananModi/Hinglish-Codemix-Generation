{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_LM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb5NCgQXvZZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6550fda7-e748-4402-abcc-b0a90fae4ec5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1Oo4Mq-tcjf"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkPLqoOubc2_",
        "outputId": "6efc2a87-351d-4a98-f888-dd3dd2e9dec4"
      },
      "source": [
        "import numpy as np\n",
        "    \n",
        "def token_lookup():\n",
        "    token_dict = {\".\":\"<period>\", \",\": \"<comma>\", \";\":\"<semicolon>\", \":\":\"<colon>\", \"\\\"\":\"<qoutation>\", \"'\":\"qoutation\", \"!\":\"<exclamation>\", \"?\":\"<question>\", \n",
        "                  \"(\": \"<leftparan>\", \")\": \"<rightparan>\", \"{\":\"leftbrace\", \"}\":\"<rightbrace>\", \"[\":\"<leftbracket>\", \"]\":\"<rightbracket>\", \"--\":\"<dash>\", \"-\":\"<hyphen>\",\n",
        "                  \"\\n\":\"<return>\"}\n",
        "    return token_dict\n",
        "\n",
        "token_dict = token_lookup()\n",
        "\n",
        "english_text = open(\"./plot.tok.gt9.5000\").read()#open(\"./plot_quote.10000\").read()\n",
        "\n",
        "for key, token in token_dict.items():\n",
        "    english_text = english_text.replace(key, ' {} '.format(token))\n",
        "english_text = english_text.lower()\n",
        "english_text = english_text.split()\n",
        "english_text = ' '.join(english_text)\n",
        "\n",
        "english_text = english_text.split(\"<period>\")\n",
        "english_text = pd.DataFrame(english_text, columns=[\"sentences\"])\n",
        "\n",
        "#hindi_text = pd.read_csv(\"./hindi_train.csv\").drop(columns=['experience']).iloc[:50]\n",
        "mix_text = open(\"./test.txt\").read()#open(\"./codemix.txt\").read()\n",
        "\n",
        "for key, token in token_dict.items():\n",
        "    mix_text = mix_text.replace(key, ' {} '.format(token))\n",
        "mix_text = mix_text.lower()\n",
        "mix_text = mix_text.split()\n",
        "mix_text = ' '.join(mix_text)\n",
        "\n",
        "mix_text = mix_text.split(\"<return>\")\n",
        "mix_text = pd.DataFrame(mix_text[:5000], columns=[\"sentences\"])\n",
        "mix_text.head"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                               sentences\n",
              "0     <qoutation> <unk> bharat me ajaad he <comma> l...\n",
              "1      indian army kashmiri logo ko nahi atankvadiyo...\n",
              "2              abbe keyo fek raha hai andhe news dalal \n",
              "3      mather chooo dukan laga ke baitha rahta hai <...\n",
              "4      jab modiji ne mudda utha hi diya ha to isko i...\n",
              "...                                                 ...\n",
              "4995   <qoutation> thappar <comma> pitai yhi <unk> k...\n",
              "4996   u and u r parti candited deserve 100 slap eve...\n",
              "4997   <qoutation> ek baar aap ko moka to do <comma>...\n",
              "4998      in fekuo ki gand me kuchh jayada hi kida hai \n",
              "4999   <qoutation> we support aap we vote aap coming...\n",
              "\n",
              "[5000 rows x 1 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "E19rBnfY4IJg",
        "outputId": "ae09edbe-db69-4cf8-d778-1ec0666eeb0e"
      },
      "source": [
        "en_mix = pd.concat([english_text, mix_text], axis=0) #mix_text \n",
        "en_mix = en_mix.sample(frac = 1)\n",
        "en_mix.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1582</th>\n",
              "      <td>very very good movie and suspense ki to bate ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>aur ghuso modi k g &lt;period&gt; &lt;period&gt; &lt;period&gt;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2839</th>\n",
              "      <td>&lt;return&gt; in their fortuitous encounter &lt;comma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2657</th>\n",
              "      <td>&lt;qoutation&gt; teri wagon r kaha hai &lt;question&gt; ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5250</th>\n",
              "      <td>&lt;return&gt; carol miller is a psychologist with ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              sentences\n",
              "1582   very very good movie and suspense ki to bate ...\n",
              "122    aur ghuso modi k g <period> <period> <period>...\n",
              "2839   <return> in their fortuitous encounter <comma...\n",
              "2657   <qoutation> teri wagon r kaha hai <question> ...\n",
              "5250   <return> carol miller is a psychologist with ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XSVWHQi8RzY",
        "outputId": "6df02c32-29b9-465d-f871-21aa75529c3c"
      },
      "source": [
        "def create_lookup_tables(text_df):\n",
        "    vocab = set()\n",
        "    for line in text_df['sentences']:\n",
        "        vocab.update(set(line.split()))\n",
        "    #vocab = set(text)\n",
        "    vocab_to_int = {c: i for i, c in enumerate(vocab)}\n",
        "    int_to_vocab = dict(enumerate(vocab))\n",
        "    return (vocab_to_int, int_to_vocab)\n",
        "\n",
        "vocab_to_int, int_to_vocab = create_lookup_tables(en_mix)\n",
        "\n",
        "train_int_text = []\n",
        "\n",
        "for line in en_mix['sentences']:\n",
        "    train_int_text.append([vocab_to_int[word] for word in line.split()])\n",
        "\n",
        "train_int_text = [item for sublist in train_int_text for item in sublist]\n",
        "print(train_int_text[:1000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[14984, 14984, 1570, 17393, 13128, 9461, 4556, 1134, 7733, 3743, 16600, 17753, 4198, 16600, 16880, 11767, 6065, 22461, 4198, 4198, 4198, 4198, 18631, 4902, 12843, 10056, 4106, 15922, 8985, 6140, 16602, 10461, 12828, 6140, 10851, 14591, 22449, 6552, 22485, 16492, 13128, 12186, 3113, 23726, 2466, 21864, 18735, 19690, 3407, 21695, 456, 18426, 445, 14965, 14965, 1275, 13788, 15322, 9969, 9860, 4556, 9236, 6063, 11883, 8523, 445, 14965, 19690, 12843, 23660, 2858, 20846, 24495, 17351, 6552, 24495, 14180, 21634, 6508, 14961, 21864, 20192, 13507, 469, 6552, 16664, 4213, 2221, 2466, 427, 7997, 7557, 4198, 4198, 488, 9844, 1889, 12488, 445, 2410, 3474, 3039, 14094, 17234, 2633, 10851, 4198, 4198, 2541, 7029, 4129, 4198, 9227, 20236, 7247, 9227, 19898, 10851, 4198, 4198, 3747, 23410, 3474, 2437, 6703, 1134, 23410, 6466, 10874, 1158, 4198, 4198, 12843, 22485, 23531, 437, 24495, 640, 22363, 13392, 6205, 6140, 11003, 9885, 1134, 3195, 22485, 20434, 18976, 22780, 16783, 14358, 10851, 5975, 22485, 640, 9227, 855, 4710, 22485, 22490, 1134, 4106, 12617, 18090, 10340, 9710, 13704, 7164, 9236, 20399, 10851, 2735, 15253, 24495, 13704, 17712, 1200, 24495, 7227, 4198, 10851, 20846, 8598, 8510, 4198, 21563, 1134, 732, 1154, 13343, 15992, 4198, 4198, 6003, 15345, 9336, 6465, 17854, 15345, 14792, 10851, 4198, 4198, 4198, 4198, 4902, 1134, 12143, 11924, 21559, 4198, 4198, 4198, 4198, 12843, 2483, 12186, 6802, 24495, 22836, 2466, 5929, 22363, 22485, 19542, 21440, 12843, 24495, 23797, 2466, 19941, 13586, 7151, 1134, 9386, 14822, 1134, 1776, 5640, 12076, 4106, 16220, 6861, 7064, 10056, 2298, 2466, 24495, 6392, 22101, 24495, 130, 2466, 4176, 24390, 12843, 13392, 15330, 13586, 13202, 10479, 17071, 14358, 21422, 5637, 12843, 9560, 18976, 22780, 7610, 16034, 10872, 13392, 24222, 439, 18976, 16729, 725, 941, 12843, 22485, 22613, 18976, 22780, 1134, 16914, 22485, 23776, 23309, 13650, 1134, 4565, 23531, 15474, 5985, 6140, 18224, 22485, 5640, 10056, 21634, 23858, 13128, 13197, 8129, 18705, 12843, 15394, 20082, 10209, 20465, 14250, 12076, 161, 6819, 6508, 10851, 20846, 12793, 24117, 13392, 11753, 21611, 17048, 10882, 24495, 19690, 21269, 5821, 7247, 2219, 20247, 7247, 10851, 12592, 7164, 10221, 1134, 21368, 637, 16845, 9236, 19690, 12843, 10056, 9386, 10612, 12186, 1614, 15156, 22485, 6602, 20096, 2466, 22485, 22248, 12526, 10851, 18976, 22780, 11049, 10056, 15843, 12028, 18162, 22461, 4198, 4198, 4198, 4198, 4198, 7164, 5413, 12310, 11397, 4198, 4198, 4198, 4198, 4198, 12487, 13311, 11603, 12436, 18162, 8716, 4855, 3208, 14880, 10335, 15322, 11289, 23247, 4198, 4198, 4198, 4198, 4198, 4198, 19690, 16121, 19815, 24566, 1134, 3981, 445, 12321, 8738, 6368, 16845, 6466, 9336, 10428, 6140, 1137, 16094, 7528, 18697, 7530, 17029, 13837, 10856, 2287, 19690, 12843, 16925, 2466, 15784, 24117, 9387, 6140, 6395, 17393, 13128, 21149, 14486, 19046, 24495, 9386, 5188, 10056, 24459, 15947, 553, 12843, 18976, 6243, 18976, 23545, 4106, 7568, 6552, 24495, 3630, 7432, 8531, 2466, 24495, 17806, 24528, 15799, 24495, 3530, 6140, 2592, 22485, 17796, 13128, 22103, 9895, 7911, 18976, 17158, 1137, 12112, 17178, 9236, 5775, 10525, 12174, 21312, 712, 10851, 22987, 3747, 22921, 13414, 3678, 20023, 14108, 5965, 18668, 12891, 17019, 2047, 12174, 17579, 6466, 8399, 15322, 13800, 3323, 16220, 17113, 12174, 12112, 4960, 17113, 12174, 12112, 824, 17291, 18697, 17291, 14191, 5024, 712, 12112, 5233, 3145, 12843, 13392, 9943, 9036, 22485, 13435, 3414, 3344, 6140, 10851, 5609, 21864, 15156, 10056, 22866, 14819, 1134, 13392, 20156, 7854, 18041, 17048, 10751, 8015, 5672, 6140, 23857, 11606, 7502, 18780, 9897, 3624, 13896, 445, 15771, 12630, 12875, 2758, 15979, 20086, 8390, 13889, 4198, 1195, 4198, 4198, 4177, 14070, 16021, 7530, 8738, 16845, 8362, 1274, 12843, 12076, 10851, 9703, 24495, 13022, 17806, 6140, 19616, 17048, 10413, 2652, 5672, 20704, 6508, 2654, 10851, 9703, 9912, 6140, 10851, 1905, 12661, 21558, 13128, 15221, 22485, 13796, 13985, 6140, 24528, 3564, 1134, 6824, 941, 21559, 13530, 4902, 24201, 6688, 10851, 17675, 22175, 11924, 23587, 20846, 19896, 23587, 9236, 17753, 17712, 11641, 463, 7797, 13211, 6466, 5568, 9336, 6171, 15029, 6063, 23857, 22836, 2280, 16991, 13095, 3474, 14240, 23587, 18487, 9236, 6654, 17888, 23797, 18631, 5024, 4902, 3039, 11172, 7577, 6764, 24351, 18697, 7706, 17178, 10851, 7164, 24495, 19690, 1275, 7530, 6121, 9227, 6029, 23594, 6248, 7674, 10340, 12736, 1274, 4556, 7514, 15464, 445, 6140, 13134, 2721, 16021, 4100, 1137, 20031, 23594, 23425, 11329, 22485, 16600, 10788, 16021, 17597, 16021, 19281, 23594, 12113, 10340, 11329, 22485, 6063, 10578, 3208, 9615, 23587, 23045, 445, 4198, 7954, 4556, 10282, 445, 6140, 10578, 24480, 24232, 23587, 3988, 8362, 5415, 18697, 4300, 4556, 4100, 4459, 11366, 18464, 445, 19690, 6863, 22836, 17366, 15531, 7530, 3731, 3482, 6654, 9580, 19275, 24117, 3208, 13128, 24117, 24495, 23750, 17597, 21368, 3451, 22379, 1498, 8725, 1586, 20735, 5585, 23587, 3125, 17231, 22921, 4198, 4198, 4198, 4198, 24588, 5729, 20846, 16034, 2466, 22485, 21077, 2491, 4230, 2466, 12815, 9132, 4198, 4198, 4198, 4198, 4198, 12843, 24459, 13840, 11270, 17265, 24495, 23861, 15619, 10056, 21864, 15250, 18976, 22780, 13128, 21864, 5258, 6140, 24528, 13586, 12178, 21558, 10056, 24495, 19245, 7502, 13128, 7502, 4070, 13950, 10143, 4106, 9386, 9386, 10612, 21903, 12076, 20236, 17659, 8169, 16977, 24117, 24495, 22023, 6613, 2466, 13473, 12843, 23690, 18976, 22780, 13022, 951, 19998, 17048, 3567, 18695, 5672, 20846, 10056, 16966, 6552, 24495, 13915, 3414, 6140, 3274, 17048, 4987, 20752, 5672, 17332, 2785, 8589, 14574, 21559, 21166, 3013, 9236, 13166, 1134, 21557, 7530, 21900, 8716, 18074, 7326, 12261, 4556, 17332, 18697, 15322, 5796, 11329, 11755, 12875, 9236, 18697, 12261, 12572, 445, 3457, 11670, 15799, 445, 21559, 18955, 21312, 775, 17970, 22836, 8511, 18623, 4198, 12256, 21485, 1134, 18162, 9016, 11579, 130, 4198, 4198, 4198, 4198, 4198, 19690, 9236, 9236, 22475, 17712, 17117, 10860, 6140, 10056, 18837, 10056, 4902, 18837, 10377, 463, 16977, 19690, 19690, 11843, 13568, 8314, 15805, 20846, 1200, 18332, 4106, 2314, 18682, 9703, 1134, 18332, 15805, 13128, 2483, 16561, 22485, 19815, 5266, 14486, 22129, 20600, 23081, 19690, 14984, 14984, 16672, 1323, 4198, 4222, 24390, 5847, 5585, 506, 19690, 17597, 23587, 15569, 22333, 22050, 9236, 4198, 22333, 7874, 1134, 785, 19690, 12843, 13639, 1134, 22314, 22485, 675, 2466, 941, 14358, 24495, 20955, 9998, 17226, 10851, 10909, 1134, 1776, 20465, 11160, 22363, 19458, 21922, 10851, 8195, 1134, 19416, 24117, 24132, 2172]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpD_QsD8D5Ri",
        "outputId": "98ecd5c0-92f1-43c7-e339-a52f98b6be10"
      },
      "source": [
        "print(en_mix.shape, len(vocab_to_int), max(train_int_text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10388, 1) 24599 24598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykY6CdowvgQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34cdfc74-8e1b-4e5e-eeb5-8675fdba3867"
      },
      "source": [
        "#import helper\n",
        "\n",
        "#data_dir = './brown.txt'\n",
        "\n",
        "#helper.preprocess_and_save_data(data_dir, token_lookup, create_lookup_tables)\n",
        "\n",
        "from distutils.version import LooseVersion\n",
        "import warnings\n",
        "#import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() \n",
        "import tensorflow as tf2\n",
        "#import helper\n",
        "import numpy as np\n",
        "\n",
        "#int_text, val_int_text, test_int_text, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()\n",
        "\n",
        "def get_inputs():\n",
        "    inputs = tf.placeholder(tf.int32, [None, None], name='input')\n",
        "    targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
        "    learn_rate = tf.placeholder(tf.float32, name='learn_rate')\n",
        "    return (inputs, targets, learn_rate)\n",
        "    \n",
        "def get_init_cell(batch_size, rnn_size):\n",
        "    def build_cell(lstm_size):\n",
        "        # Use a basic LSTM cell\n",
        "        lstm = tf2.compat.v1.nn.rnn_cell.BasicLSTMCell(lstm_size)\n",
        "        \n",
        "        # Add dropout to the cell\n",
        "        drop = tf2.compat.v1.nn.rnn_cell.DropoutWrapper(lstm)#, output_keep_prob=keep_prob)\n",
        "        return drop\n",
        "    \n",
        "    \n",
        "    # Stack up multiple LSTM layers, for deep learning\n",
        "    num_layers = 2\n",
        "    cell = tf2.compat.v1.nn.rnn_cell.MultiRNNCell([build_cell(rnn_size) for _ in range(num_layers)])\n",
        "    initial_state = cell.zero_state(batch_size, dtype=tf.float32)\n",
        "    initial_state = tf.identity(initial_state, name=\"initial_state\")\n",
        "    return (cell, initial_state)\n",
        "    \n",
        "def get_embed(input_data, vocab_size, embed_dim):\n",
        "    embedding = tf.Variable(tf.random_uniform((vocab_size, embed_dim), -1, 1))\n",
        "    embed = tf.nn.embedding_lookup(embedding, input_data)\n",
        "    return embed\n",
        "    \n",
        "def build_rnn(cell, inputs):\n",
        "    outputs, final_state = tf.nn.dynamic_rnn(cell, inputs, dtype=tf.float32)#,initial_state=initial_state)\n",
        "    final_state = tf.identity(final_state, name=\"final_state\")\n",
        "    return outputs, final_state\n",
        "    \n",
        "def build_nn(cell, rnn_size, input_data, vocab_size, embed_dim):\n",
        "    embed = get_embed(input_data, vocab_size, embed_dim)\n",
        "    outputs, final_state = build_rnn(cell, embed)\n",
        "    \n",
        "    logits = tf2.compat.v1.layers.dense(outputs, vocab_size, activation=None)\n",
        "    return logits, final_state\n",
        "    \n",
        "def get_batches(int_text, batch_size, seq_length):\n",
        "    words_per_batch = batch_size * seq_length\n",
        "    num_batch = len(int_text)//words_per_batch\n",
        "    \n",
        "    input_text = np.array(int_text[:(num_batch*words_per_batch)])\n",
        "    target_text = np.array(int_text[1:(num_batch * words_per_batch) + 1])\n",
        "\n",
        "    target_text[-1] = input_text[0]\n",
        "    \n",
        "    x_batches = np.split(input_text.reshape(batch_size, -1), num_batch, 1)\n",
        "    y_batches = np.split(target_text.reshape(batch_size, -1), num_batch, 1)\n",
        "    \n",
        "    batches = np.array(list(zip(x_batches, y_batches)))\n",
        "    return batches\n",
        "    \n",
        "# Number of Epochs\n",
        "num_epochs = 50\n",
        "# Batch Size\n",
        "batch_size = 100\n",
        "# RNN Size\n",
        "rnn_size = 512\n",
        "# Embedding Dimension Size\n",
        "embed_dim = 256\n",
        "# Sequence Length\n",
        "seq_length = 15\n",
        "# Learning Rate\n",
        "learning_rate = 0.001\n",
        "# Show stats for every n number of batches\n",
        "show_every_n_batches = 50\n",
        "\n",
        "save_dir = '/content/drive/MyDrive/nlp_project/models/model_1_en_en/save'\n",
        "\n",
        "batches = get_batches(train_int_text, batch_size, seq_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIVh3N-SLMF6",
        "outputId": "3012eb1a-2804-45bd-b88e-a821e804b6cc"
      },
      "source": [
        "!pip install tensorflow_addons\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "\n",
        "train_graph = tf.Graph()\n",
        "with train_graph.as_default():\n",
        "    vocab_size = len(int_to_vocab)\n",
        "    input_text, targets, lr = get_inputs()\n",
        "    input_data_shape = tf.shape(input_text)\n",
        "    cell, initial_state = get_init_cell(input_data_shape[0], rnn_size)\n",
        "    logits, final_state = build_nn(cell, rnn_size, input_text, vocab_size, embed_dim)\n",
        "\n",
        "    # Probabilities for generating words\n",
        "    probs = tf.nn.softmax(logits, name='probs')\n",
        "\n",
        "    # Loss function\n",
        "    cost = tfa.seq2seq.sequence_loss(\n",
        "        logits,\n",
        "        targets,\n",
        "        tf.ones([input_data_shape[0], input_data_shape[1]]))\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = tf.train.AdamOptimizer(lr)\n",
        "\n",
        "    # Gradient Clipping\n",
        "    gradients = optimizer.compute_gradients(cost)\n",
        "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
        "    train_op = optimizer.apply_gradients(capped_gradients)\n",
        "    \n",
        "#batches = get_batches(train_int_text, batch_size, seq_length)\n",
        "#train_graph = tf.Graph()\n",
        "with tf.Session(graph=train_graph) as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for epoch_i in range(num_epochs):\n",
        "        state = sess.run(initial_state, {input_text: batches[0][0]})\n",
        "\n",
        "        for batch_i, (x, y) in enumerate(batches):\n",
        "            feed = {\n",
        "                input_text: x,\n",
        "                targets: y,\n",
        "                initial_state: state,\n",
        "                lr: learning_rate}\n",
        "            train_loss, state, _ = sess.run([cost, final_state, train_op], feed)\n",
        "\n",
        "            # Show every <show_every_n_batches> batches\n",
        "            if (epoch_i * len(batches) + batch_i) % show_every_n_batches == 0:\n",
        "                print('Epoch {:>3} Batch {:>4}/{}   train_loss = {:.3f}'.format(\n",
        "                    epoch_i,\n",
        "                    batch_i,\n",
        "                    len(batches),\n",
        "                    train_loss))\n",
        "\n",
        "    # Save Model\n",
        "    saver = tf.train.Saver()\n",
        "    saver.save(sess, save_dir)\n",
        "    print('Model Trained and Saved')\n",
        "    \n",
        "# Save parameters for checkpoint\n",
        "#helper.save_params((seq_length, save_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/e3/56d2fe76f0bb7c88ed9b2a6a557e25e83e252aec08f13de34369cd850a0b/tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703kB)\n",
            "\r\u001b[K     |▌                               | 10kB 20.2MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 27.2MB/s eta 0:00:01\r\u001b[K     |█▍                              | 30kB 21.6MB/s eta 0:00:01\r\u001b[K     |█▉                              | 40kB 20.2MB/s eta 0:00:01\r\u001b[K     |██▎                             | 51kB 21.4MB/s eta 0:00:01\r\u001b[K     |██▉                             | 61kB 16.2MB/s eta 0:00:01\r\u001b[K     |███▎                            | 71kB 17.2MB/s eta 0:00:01\r\u001b[K     |███▊                            | 81kB 17.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 92kB 15.6MB/s eta 0:00:01\r\u001b[K     |████▋                           | 102kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 112kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 122kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 133kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 143kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 153kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 163kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 174kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 184kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 194kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 204kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 215kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 225kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 235kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 245kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 256kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 266kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 276kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 286kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 296kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 307kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 317kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 327kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 337kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 348kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 358kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 368kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 378kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 389kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 399kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 409kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 419kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 430kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 440kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 450kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 460kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 471kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 481kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 491kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 501kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 512kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 522kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 532kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 542kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 552kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 563kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 573kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 583kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 593kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 604kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 614kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 624kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 634kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 645kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 655kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 665kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 675kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 686kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 696kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 706kB 16.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.12.1\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-9-b3696798174b>:47: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:753: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:702: UserWarning: `tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  warnings.warn(\"`tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch   0 Batch    0/168   train_loss = 10.110\n",
            "Epoch   0 Batch   50/168   train_loss = 7.921\n",
            "Epoch   0 Batch  100/168   train_loss = 7.588\n",
            "Epoch   0 Batch  150/168   train_loss = 7.479\n",
            "Epoch   1 Batch   32/168   train_loss = 7.201\n",
            "Epoch   1 Batch   82/168   train_loss = 7.012\n",
            "Epoch   1 Batch  132/168   train_loss = 6.829\n",
            "Epoch   2 Batch   14/168   train_loss = 6.593\n",
            "Epoch   2 Batch   64/168   train_loss = 6.663\n",
            "Epoch   2 Batch  114/168   train_loss = 6.660\n",
            "Epoch   2 Batch  164/168   train_loss = 6.376\n",
            "Epoch   3 Batch   46/168   train_loss = 6.433\n",
            "Epoch   3 Batch   96/168   train_loss = 6.226\n",
            "Epoch   3 Batch  146/168   train_loss = 6.123\n",
            "Epoch   4 Batch   28/168   train_loss = 6.262\n",
            "Epoch   4 Batch   78/168   train_loss = 6.147\n",
            "Epoch   4 Batch  128/168   train_loss = 5.928\n",
            "Epoch   5 Batch   10/168   train_loss = 6.054\n",
            "Epoch   5 Batch   60/168   train_loss = 5.822\n",
            "Epoch   5 Batch  110/168   train_loss = 5.784\n",
            "Epoch   5 Batch  160/168   train_loss = 5.805\n",
            "Epoch   6 Batch   42/168   train_loss = 5.602\n",
            "Epoch   6 Batch   92/168   train_loss = 5.675\n",
            "Epoch   6 Batch  142/168   train_loss = 5.600\n",
            "Epoch   7 Batch   24/168   train_loss = 5.559\n",
            "Epoch   7 Batch   74/168   train_loss = 5.427\n",
            "Epoch   7 Batch  124/168   train_loss = 5.566\n",
            "Epoch   8 Batch    6/168   train_loss = 5.241\n",
            "Epoch   8 Batch   56/168   train_loss = 5.223\n",
            "Epoch   8 Batch  106/168   train_loss = 5.256\n",
            "Epoch   8 Batch  156/168   train_loss = 5.262\n",
            "Epoch   9 Batch   38/168   train_loss = 5.121\n",
            "Epoch   9 Batch   88/168   train_loss = 5.187\n",
            "Epoch   9 Batch  138/168   train_loss = 5.036\n",
            "Epoch  10 Batch   20/168   train_loss = 5.082\n",
            "Epoch  10 Batch   70/168   train_loss = 4.822\n",
            "Epoch  10 Batch  120/168   train_loss = 4.855\n",
            "Epoch  11 Batch    2/168   train_loss = 4.708\n",
            "Epoch  11 Batch   52/168   train_loss = 4.876\n",
            "Epoch  11 Batch  102/168   train_loss = 4.712\n",
            "Epoch  11 Batch  152/168   train_loss = 4.629\n",
            "Epoch  12 Batch   34/168   train_loss = 4.782\n",
            "Epoch  12 Batch   84/168   train_loss = 4.491\n",
            "Epoch  12 Batch  134/168   train_loss = 4.525\n",
            "Epoch  13 Batch   16/168   train_loss = 4.316\n",
            "Epoch  13 Batch   66/168   train_loss = 4.341\n",
            "Epoch  13 Batch  116/168   train_loss = 4.402\n",
            "Epoch  13 Batch  166/168   train_loss = 4.425\n",
            "Epoch  14 Batch   48/168   train_loss = 4.276\n",
            "Epoch  14 Batch   98/168   train_loss = 4.123\n",
            "Epoch  14 Batch  148/168   train_loss = 4.040\n",
            "Epoch  15 Batch   30/168   train_loss = 3.987\n",
            "Epoch  15 Batch   80/168   train_loss = 4.005\n",
            "Epoch  15 Batch  130/168   train_loss = 4.090\n",
            "Epoch  16 Batch   12/168   train_loss = 3.940\n",
            "Epoch  16 Batch   62/168   train_loss = 3.889\n",
            "Epoch  16 Batch  112/168   train_loss = 3.874\n",
            "Epoch  16 Batch  162/168   train_loss = 3.835\n",
            "Epoch  17 Batch   44/168   train_loss = 3.743\n",
            "Epoch  17 Batch   94/168   train_loss = 3.599\n",
            "Epoch  17 Batch  144/168   train_loss = 3.575\n",
            "Epoch  18 Batch   26/168   train_loss = 3.559\n",
            "Epoch  18 Batch   76/168   train_loss = 3.523\n",
            "Epoch  18 Batch  126/168   train_loss = 3.332\n",
            "Epoch  19 Batch    8/168   train_loss = 3.387\n",
            "Epoch  19 Batch   58/168   train_loss = 3.433\n",
            "Epoch  19 Batch  108/168   train_loss = 3.301\n",
            "Epoch  19 Batch  158/168   train_loss = 3.160\n",
            "Epoch  20 Batch   40/168   train_loss = 3.212\n",
            "Epoch  20 Batch   90/168   train_loss = 3.058\n",
            "Epoch  20 Batch  140/168   train_loss = 2.996\n",
            "Epoch  21 Batch   22/168   train_loss = 3.090\n",
            "Epoch  21 Batch   72/168   train_loss = 2.948\n",
            "Epoch  21 Batch  122/168   train_loss = 2.900\n",
            "Epoch  22 Batch    4/168   train_loss = 2.857\n",
            "Epoch  22 Batch   54/168   train_loss = 2.744\n",
            "Epoch  22 Batch  104/168   train_loss = 2.856\n",
            "Epoch  22 Batch  154/168   train_loss = 2.725\n",
            "Epoch  23 Batch   36/168   train_loss = 2.686\n",
            "Epoch  23 Batch   86/168   train_loss = 2.563\n",
            "Epoch  23 Batch  136/168   train_loss = 2.570\n",
            "Epoch  24 Batch   18/168   train_loss = 2.558\n",
            "Epoch  24 Batch   68/168   train_loss = 2.476\n",
            "Epoch  24 Batch  118/168   train_loss = 2.443\n",
            "Epoch  25 Batch    0/168   train_loss = 2.394\n",
            "Epoch  25 Batch   50/168   train_loss = 2.295\n",
            "Epoch  25 Batch  100/168   train_loss = 2.273\n",
            "Epoch  25 Batch  150/168   train_loss = 2.170\n",
            "Epoch  26 Batch   32/168   train_loss = 2.231\n",
            "Epoch  26 Batch   82/168   train_loss = 2.177\n",
            "Epoch  26 Batch  132/168   train_loss = 2.137\n",
            "Epoch  27 Batch   14/168   train_loss = 2.090\n",
            "Epoch  27 Batch   64/168   train_loss = 2.134\n",
            "Epoch  27 Batch  114/168   train_loss = 1.915\n",
            "Epoch  27 Batch  164/168   train_loss = 2.074\n",
            "Epoch  28 Batch   46/168   train_loss = 1.981\n",
            "Epoch  28 Batch   96/168   train_loss = 1.918\n",
            "Epoch  28 Batch  146/168   train_loss = 1.907\n",
            "Epoch  29 Batch   28/168   train_loss = 1.732\n",
            "Epoch  29 Batch   78/168   train_loss = 1.747\n",
            "Epoch  29 Batch  128/168   train_loss = 1.766\n",
            "Epoch  30 Batch   10/168   train_loss = 1.646\n",
            "Epoch  30 Batch   60/168   train_loss = 1.695\n",
            "Epoch  30 Batch  110/168   train_loss = 1.611\n",
            "Epoch  30 Batch  160/168   train_loss = 1.625\n",
            "Epoch  31 Batch   42/168   train_loss = 1.545\n",
            "Epoch  31 Batch   92/168   train_loss = 1.567\n",
            "Epoch  31 Batch  142/168   train_loss = 1.506\n",
            "Epoch  32 Batch   24/168   train_loss = 1.443\n",
            "Epoch  32 Batch   74/168   train_loss = 1.510\n",
            "Epoch  32 Batch  124/168   train_loss = 1.413\n",
            "Epoch  33 Batch    6/168   train_loss = 1.434\n",
            "Epoch  33 Batch   56/168   train_loss = 1.384\n",
            "Epoch  33 Batch  106/168   train_loss = 1.482\n",
            "Epoch  33 Batch  156/168   train_loss = 1.296\n",
            "Epoch  34 Batch   38/168   train_loss = 1.310\n",
            "Epoch  34 Batch   88/168   train_loss = 1.180\n",
            "Epoch  34 Batch  138/168   train_loss = 1.215\n",
            "Epoch  35 Batch   20/168   train_loss = 1.213\n",
            "Epoch  35 Batch   70/168   train_loss = 1.229\n",
            "Epoch  35 Batch  120/168   train_loss = 1.085\n",
            "Epoch  36 Batch    2/168   train_loss = 1.136\n",
            "Epoch  36 Batch   52/168   train_loss = 1.115\n",
            "Epoch  36 Batch  102/168   train_loss = 1.043\n",
            "Epoch  36 Batch  152/168   train_loss = 1.033\n",
            "Epoch  37 Batch   34/168   train_loss = 0.885\n",
            "Epoch  37 Batch   84/168   train_loss = 0.955\n",
            "Epoch  37 Batch  134/168   train_loss = 0.916\n",
            "Epoch  38 Batch   16/168   train_loss = 0.922\n",
            "Epoch  38 Batch   66/168   train_loss = 0.804\n",
            "Epoch  38 Batch  116/168   train_loss = 0.775\n",
            "Epoch  38 Batch  166/168   train_loss = 0.856\n",
            "Epoch  39 Batch   48/168   train_loss = 0.810\n",
            "Epoch  39 Batch   98/168   train_loss = 0.687\n",
            "Epoch  39 Batch  148/168   train_loss = 0.776\n",
            "Epoch  40 Batch   30/168   train_loss = 0.721\n",
            "Epoch  40 Batch   80/168   train_loss = 0.779\n",
            "Epoch  40 Batch  130/168   train_loss = 0.682\n",
            "Epoch  41 Batch   12/168   train_loss = 0.789\n",
            "Epoch  41 Batch   62/168   train_loss = 0.662\n",
            "Epoch  41 Batch  112/168   train_loss = 0.606\n",
            "Epoch  41 Batch  162/168   train_loss = 0.662\n",
            "Epoch  42 Batch   44/168   train_loss = 0.662\n",
            "Epoch  42 Batch   94/168   train_loss = 0.672\n",
            "Epoch  42 Batch  144/168   train_loss = 0.622\n",
            "Epoch  43 Batch   26/168   train_loss = 0.581\n",
            "Epoch  43 Batch   76/168   train_loss = 0.597\n",
            "Epoch  43 Batch  126/168   train_loss = 0.541\n",
            "Epoch  44 Batch    8/168   train_loss = 0.624\n",
            "Epoch  44 Batch   58/168   train_loss = 0.522\n",
            "Epoch  44 Batch  108/168   train_loss = 0.558\n",
            "Epoch  44 Batch  158/168   train_loss = 0.482\n",
            "Epoch  45 Batch   40/168   train_loss = 0.558\n",
            "Epoch  45 Batch   90/168   train_loss = 0.513\n",
            "Epoch  45 Batch  140/168   train_loss = 0.507\n",
            "Epoch  46 Batch   22/168   train_loss = 0.519\n",
            "Epoch  46 Batch   72/168   train_loss = 0.468\n",
            "Epoch  46 Batch  122/168   train_loss = 0.472\n",
            "Epoch  47 Batch    4/168   train_loss = 0.465\n",
            "Epoch  47 Batch   54/168   train_loss = 0.420\n",
            "Epoch  47 Batch  104/168   train_loss = 0.455\n",
            "Epoch  47 Batch  154/168   train_loss = 0.400\n",
            "Epoch  48 Batch   36/168   train_loss = 0.462\n",
            "Epoch  48 Batch   86/168   train_loss = 0.407\n",
            "Epoch  48 Batch  136/168   train_loss = 0.407\n",
            "Epoch  49 Batch   18/168   train_loss = 0.400\n",
            "Epoch  49 Batch   68/168   train_loss = 0.377\n",
            "Epoch  49 Batch  118/168   train_loss = 0.393\n",
            "Model Trained and Saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mydjHeLA5MHa",
        "outputId": "a8ba08ba-95e6-4197-8a89-13323c0f4f45"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "#import helper\n",
        "\n",
        "def pick_word(probabilities, int_to_vocab):\n",
        "    \"\"\"\n",
        "    Pick the next word in the generated text\n",
        "    :param probabilities: Probabilites of the next word\n",
        "    :param int_to_vocab: Dictionary of word ids as the keys and words as the values\n",
        "    :return: String of the predicted word\n",
        "    \"\"\"\n",
        "    # TODO: Implement Function\n",
        "    index = np.where(probabilities == np.max(probabilities))[-1][0]\n",
        "\n",
        "    return int_to_vocab[index]\n",
        "\n",
        "#_,_,_, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()\n",
        "seq_length, load_dir = 15, '/content/drive/MyDrive/nlp_project/models/model_1_en_en/save'\n",
        "def get_tensors(loaded_graph):\n",
        "    input_tensor = loaded_graph.get_tensor_by_name(\"input:0\")\n",
        "    initial_state_tensor = loaded_graph.get_tensor_by_name(\"initial_state:0\")\n",
        "    final_state_tensor = loaded_graph.get_tensor_by_name(\"final_state:0\")\n",
        "    prob_tensor = loaded_graph.get_tensor_by_name(\"probs:0\")\n",
        "\n",
        "    return input_tensor, initial_state_tensor, final_state_tensor, prob_tensor\n",
        "    \n",
        "#test_text = [int_to_vocab[word] for word in test_int_text]\n",
        "#test_text = \" \".join(test_text)\n",
        "#test_sent_text = test_text.split(\"<period>\")\n",
        "\n",
        "'''\n",
        "test_sentences = input(\"Enter sentence:\")\n",
        "token_dict = token_lookup()\n",
        "for key, token in token_dict.items():\n",
        "\ttest_sentences = test_sentences.replace(key, ' {} '.format(token))\n",
        "test_sentences = test_sentences.lower()\n",
        "test_sentences = test_sentences.split(\"<period>\")\n",
        "'''\n",
        "#all_perp = []\n",
        "\n",
        "loaded_graph = tf.Graph()\n",
        "with tf.compat.v1.Session(graph=loaded_graph) as sess:\n",
        "    # Load saved model\n",
        "    loader = tf.compat.v1.train.import_meta_graph(load_dir + '.meta')\n",
        "    loader.restore(sess, load_dir)\n",
        "\n",
        "    # Get Tensors from loaded model\n",
        "    input_text, initial_state, final_state, probs = get_tensors(loaded_graph)\n",
        "    #print(final_state)\n",
        "    # Sentences generation setup\n",
        "    gen_length = 4000\n",
        "    prime_word = 'bharat' #'यही' #'moe_szyslak'\n",
        "    gen_sentences = [prime_word]\n",
        "            \n",
        "    prev_state = sess.run(initial_state, {input_text: np.array([[1]])})\n",
        "\n",
        "    # Generate sentences\n",
        "    for n in range(gen_length):\n",
        "        # Dynamic Input\n",
        "        dyn_input = [[vocab_to_int[word] for word in gen_sentences[-seq_length:]]]\n",
        "        dyn_seq_length = len(dyn_input[0])\n",
        "          \n",
        "        # Get Prediction\n",
        "        probabilities, prev_state = sess.run(\n",
        "            [probs, final_state],\n",
        "            {input_text: dyn_input, initial_state: prev_state})\n",
        "\n",
        "        #pred_word = pick_word(probabilities[0][dyn_seq_length-1], int_to_vocab)\n",
        "        pred_word = pick_word(probabilities[0][dyn_seq_length-1], int_to_vocab)\n",
        "\n",
        "        gen_sentences.append(pred_word)\n",
        "\n",
        "    # Remove tokens\n",
        "    tv_script = ' '.join(gen_sentences)\n",
        "    for key, token in token_dict.items():\n",
        "        if key=='.':\n",
        "            tv_script = tv_script.replace(' ' + token.lower(), '\\n')\n",
        "        else:\n",
        "            ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
        "            tv_script = tv_script.replace(' ' + token.lower(), key)\n",
        "    tv_script = tv_script.replace('\\n ', '')\n",
        "    tv_script = tv_script.replace('( ', '(')\n",
        "        \n",
        "    print(tv_script)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/nlp_project/models/model_1_en_en/save\n",
            "bharat hai sir ji\n",
            "\n",
            "me ye <unk> hai, <unk> tu tum mat hoga <unk> dub ho ki desh me jo kyu hi diya hain ki jo asliyat abhi log samjhenge ki meri apne pura kare hi nahi to jaise rules jaha log desh ko support kar rahe hin\n",
            "\n",
            "jab mla take punjab chalane ki kaam krna haiand now, in an dogs, he was turned into the scary and childhood and run to the same time for his father' s to it outhe is the story of a young girl who have about play a luck at the world of their passion- a new war of middle class on the store of people as a group of prostitutes' s death as one of his own, but tried to live him the other plans of successlilli grew into an internet moments of a bizarre world picnic; this documentary about b small town show sir arvind kejriwal\" to see with you sir <unk> will <unk>(ak) out of india <unk> v ctusip m b 1 nd plan\n",
            "\n",
            "thank you sirab kuch nhi <unk> jaagti hai kya\n",
            "\" the brideshe was a dark comedy on the school when she must find battle and he has it' sthe daughter is the story of in this criminal, who could only work in the drug-' s underworld as brother as the teen try, most of course of another friends, and everyone up to stay a trip to meet the evilbut she was meets every after the story of a drug lord is about to fight over with the federationafter her mother is able to make no way to the big screen(rebecca) and her two sister, sean are passionate about to their own livesnow the bomb turns into the help of her art and tom black fighter\" congratulation aap ka matlab bhi mujhe badal jana br jo main diye review nhi thi\n",
            "this girl not congressgod bless u should get name electricity\n",
            "\n",
            "\n",
            "you have vry shrt memory\n",
            ", i love you mouni in victory of cinema such as people both other words amir sir\n",
            "\n",
            "however, after next place to play the hottest issues of three men, he moves it into a person that she has to overcome her fatherhe is a full- player starring actor of jack, who he is now the army is a witness to a new black nahi se pm free karo aur <unk> ke liye<unk> main sab ka kya hogathis dark comedy about a story about a young woman who becomes thirty to meet a\" shallow gun and i have not only that this is it\n",
            "\n",
            "for your party\n",
            "\n",
            "\n",
            "i think siriya can do that man may <unk>however, when some man from mnemosyne, the experiences respects struck his wife to death, but everything has them just odd having to the house of her friends and family of trouble- or all people' s great weekstwo couples decide to make everything get out of the old social friends teams up from the little beautiful underworld mrplease help karo sir u r d best 21 to resign se hi di, jo logon ke bahane film karebogus baar sirf <unk> party ki tax kaisi hi dekh lo\n",
            "\n",
            "so jab kaan kar sakte he\n",
            "\n",
            "jab bhi kuch kiraye ki baari hai\n",
            "\n",
            "a puppet of muslim <unk> who also wait behind saying model survey arvindji tak kab is desh me hi joda jana hai\" are sir, so you get it\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "so what r u doing and will win if u are best of u sir har <unk> ke logon ko hi rajiv gandhi sb bhi kisi ki <unk> kojae use mai jab aap hi kregakya pak ki jarurat nhi jo duniya mein chaiye its on u\n",
            "the war of the ring has been begun to rob the fate of the evil knightnow it seems for the next traffic menace\" bhai jhutha saal etcdo n' t worryplease go on ur new luk\n",
            "\"all her dreams long little time shared their second year from the desertin exchange for a california prison, one of the warm friends' s daughter, who has become no real foreverand the journey are teased and tim collecting to the court 2002 out of his jaded and members of their own gold; kilo lives as a while seven- out are gone away to get the agency to finish a body guard shop to file pm hi ye <unk> rule\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "best story for <unk>\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "not like you only\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tFD5qlb52Ox"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}