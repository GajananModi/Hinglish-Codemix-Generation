{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Nlp_Assignmet2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiNnDAvIg6dw"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN9-XePA4uqi",
        "outputId": "efd3abeb-ad51-42b3-d470-837a62798f7a"
      },
      "source": [
        "! pip install nltk  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJH2lIodF34l"
      },
      "source": [
        "- Create array of strings . seperated\n",
        "- code need to be updated (not optimised one sequential things neeed to implement nparray with broadcast)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__ZST7FqMS4i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fe7a96c-eea0-4737-8f01-104aa8e1a995"
      },
      "source": [
        "a_file = \"/content/drive/MyDrive/Classification/Normalise_Data/0codemix.txt\"\n",
        "response = open(a_file).read()\n",
        "response = response.lower()\n",
        "response=response.replace('\\n','')\n",
        "data = response.split('.')\n",
        "\n",
        "print(len(data))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "6FapfklYJ0mE",
        "outputId": "8cfee9cc-c078-4191-d34d-cc8563616090"
      },
      "source": [
        "response[:1500]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the biggest drawback of इस योजना is that इस सब्सिडी is not एक बड़ी खामी up with महंगाई दर . दिल्ली is an urban territory . there banks are in बैंक बहुतायत and most of अधिकांश लोगों पास also have bank accounts . यही बात can also be said about आधार कार्ड भी . but various complaints are आ रही हैं up in other territories of देश . the most important सबसे जरूरी बात is that the needy will only मिलेगा , पैसा if their fingerprint matches the database of uidai . now , let us look at the ground reality . the reality of कोटकासिम तहसील of अलवर जिले is before us . in the four districts of झारखंड भी also - हजारीबाग and सरायकेला पायलट परियोजना was शुरू since last december . in ramgarh , the laborers of मनरेगा were supposed to get मजदूरी on आधार of आधार कार्ड . there are one lakh , seventy four thousand मजदूर but even after एक साल बाद भी only five thousand मजदूर have been successfully linked with aadhar card . despite this if केंद्र सरकार is in जल्दबाजी to come up with कैश सब्सिडी योजना , this means that इसके wants to take चुनावी लाभ of elections . if it thinks that it can again come into power because of मनरेगा , then why cant योजना make the trio of यूपीए . congress is busy in playing the tactics so that भाजपा शासित राज्य should not take its advantage . actually during मनरेगा योजना दौरान , the chief ministers of भाजपा शासित राज्यों put up their pictures in the manrega posters . despite the efforts of कांग्रेस , in जल्दबाजी कैश सब्सिडी योजना will definitely होगा a wastage . the 65 rupees incr'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Gr6pjPpnpBvB",
        "outputId": "d53625e2-c2a8-4b83-c904-0499c0981efb"
      },
      "source": [
        "data[200]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' वाष्प was also easily available '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Fte2Ex35mTZN",
        "outputId": "bde9a7b9-cd20-472a-da90-4742d85c6bda"
      },
      "source": [
        "data = \" \".join(data)\n",
        "data[:200]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the biggest drawback of इस योजना is that इस सब्सिडी is not एक बड़ी खामी up with महंगाई दर   दिल्ली is an urban territory   there banks are in बैंक बहुतायत and most of अधिकांश लोगों पास also have bank '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvB7dujSGUOq"
      },
      "source": [
        "- Simple cleaning and tokenisation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOG7CxGGKGpt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93947cdf-1820-4481-df41-c0a57beb672b"
      },
      "source": [
        "def clean_text(doc):\n",
        " \n",
        "  tokens = doc.split()\n",
        "  #table = str.maketrans('', '', string.punctuation)\n",
        "  #tokens = [w.translate(table) for w in tokens]\n",
        "  #tokens = [word for word in tokens if word.isalpha()]\n",
        "  #tokens = [word.lower() for word in tokens]\n",
        "  return tokens\n",
        "\n",
        "tokens = clean_text(data)\n",
        "print(tokens[:50])\n",
        "print(len(tokens))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['the', 'biggest', 'drawback', 'of', 'इस', 'योजना', 'is', 'that', 'इस', 'सब्सिडी', 'is', 'not', 'एक', 'बड़ी', 'खामी', 'up', 'with', 'महंगाई', 'दर', 'दिल्ली', 'is', 'an', 'urban', 'territory', 'there', 'banks', 'are', 'in', 'बैंक', 'बहुतायत', 'and', 'most', 'of', 'अधिकांश', 'लोगों', 'पास', 'also', 'have', 'bank', 'accounts', 'यही', 'बात', 'can', 'also', 'be', 'said', 'about', 'आधार', 'कार्ड', 'भी']\n",
            "243873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpV0cdPqKU2m"
      },
      "source": [
        "length = 50 + 1\n",
        "lines = []\n",
        "\n",
        "for i in range(length, len(tokens)):\n",
        "  seq = tokens[i-length:i]\n",
        "  line = ' '.join(seq)\n",
        "  lines.append(line)\n",
        "  if i > 90000:\n",
        "    break\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03rBVpUTwOSz",
        "outputId": "ae55c578-17b9-4a42-96b1-28e412f8a4a3"
      },
      "source": [
        "len(lines)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "89951"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GFk2zEhn5lL",
        "outputId": "8c788fa8-9f6f-47f7-e545-e1d1ab3f30d5"
      },
      "source": [
        "seed_text='from what i was able to gauge in a swift, greedy glance, the figure inside the coral-colored boucle dress was stupefying'\n",
        "#pp=[]\n",
        "pp1=[]\n",
        "temp=0.0\n",
        "b_file = \"/content/drive/MyDrive/Classification/train3.txt\"\n",
        "the_file= open(b_file, \"w\")\n",
        "\n",
        "for i in range(10000,20000):\n",
        "  #seed_text=data[i]\n",
        "  lines3=[]\n",
        "  the_file.write(data[i]+'\\t')\n",
        "  lines3.append(data[i])\n",
        "  try:\n",
        "    temp=evaluate(lines3,50)\n",
        "    the_file.write(str(temp))\n",
        "    pp1.append(temp)\n",
        "    print(temp)\n",
        "  except:\n",
        "    pp1.append(0)\n",
        "  the_file.write('\\n')\n",
        "the_file.write('Avg'+'\\t'+str(sum(pp1)/len(pp1)))\n",
        "the_file.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.42807135710166\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3aa9eadb00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "12.42825909946579\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3aa8f45d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3.9360539284103866\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3aa8b69e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1.4415158978539373\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3aa8c2f830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3.219409138823925\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3aaa3cb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "12.398935550450657\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3aa7a29f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1.2442108961557563\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3aa8a46a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1.5078469805654393\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3aa95f8f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1.10236660276119\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3aaa581c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1.1559629721308398\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3aa7c11b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "12.42068149231349\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3aa77efe60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1.176420337384717\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3aaa581e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "11.992827669094524\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3aa8a464d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1.3126516047895191\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3aa8ac04d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3.6148223957930803\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3aa7d69c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3.5795749500629173\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3aa7000cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2.5786681004826066\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3aa89ef8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1.6098337991052492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDnWcpcAgzp5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb911a5c-b177-4528-8450-44ebf057057a"
      },
      "source": [
        "print(sum(pp)/len(pp)) #traning Data "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5292204323351353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dzgE3mjDGAn"
      },
      "source": [
        "def evaluate(lines,text_seq_length):\n",
        "  \n",
        "  model1 = load_model('/content/drive/MyDrive/Classification/model.h5')\n",
        "  # load the tokenizer\n",
        "  tokenizer1 = load(open('/content/drive/MyDrive/Classification/tokenizer.pkl', 'rb'))\n",
        "  sequences = tokenizer1.texts_to_sequences(lines)\n",
        "  sequences = np.array(sequences)\n",
        "  X, y = sequences[:, :-1], sequences[:,-1]\n",
        "  vocab_size = len(tokenizer1.word_index) + 1\n",
        "  y = to_categorical(y, num_classes=vocab_size)\n",
        "  encoded = tokenizer1.texts_to_sequences(lines)[0]\n",
        "  encoded = pad_sequences([encoded], maxlen = text_seq_length, truncating='pre')\n",
        "  y_predict = model1.predict(encoded)\n",
        "  pp=perplexity2(y.flatten(),y_predict.flatten())\n",
        "  return pp\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42p2F2VsqUH1",
        "outputId": "6523b9ae-9954-4f54-d7cb-50c87f02cdcf"
      },
      "source": [
        "print(sum(pp)/len(pp))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.253420611171959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52nV4LW4KYbJ"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5NYxWtYBWqG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qPqYyOsKdEw"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(np.array(lines))\n",
        "sequences = tokenizer.texts_to_sequences(lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wdtwxqk4RfMP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b962126-6218-415e-a1bc-fe0ccd2d119b"
      },
      "source": [
        "print(sequences[20][2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71K3ewFpI5w8"
      },
      "source": [
        "result=[]\n",
        "for d in sequences:\n",
        "  if(len(d) == 51):\n",
        "    result.append(d)\n",
        "  \n",
        "\n",
        "r1=np.array(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvnFczsH3V8r",
        "outputId": "950d2cfb-1056-4b55-a97c-8852945a133a"
      },
      "source": [
        "r1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28152, 51)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS1iloLLKgIo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfbf1ad3-6658-4a34-9f51-27cc94f494e1"
      },
      "source": [
        "X, y = r1[:, :-1], r1[:,-1]\n",
        "print(r1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28152, 51)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrWi0lPEx53g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1918cd50-d85f-44e6-e6e1-da8567682b8d"
      },
      "source": [
        "X[20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   3,  182, 9585, 5068,   15, 5067,    7,    2,  507, 2818,    5,\n",
              "        194,    1,  985,  545,  611,   18,   28, 3569, 9582,  764,  506,\n",
              "         42,   18,   14,  408,  308,  189, 2816,   21,   34,  235, 5070,\n",
              "          7,  546,  297,   84,  179,    2,  169, 3573,    1,   43,    4,\n",
              "        194,  285,  286, 5071,  506,    3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bic17g0LKkCO"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyVZfTvnh6Nz",
        "outputId": "5d769a1d-3518-4275-dadc-6da6e8508c7a"
      },
      "source": [
        "print(vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhwtuVUhKnU9"
      },
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecF4jTuVKqkq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "908e8820-953e-4352-e8f7-a18fb1eac012"
      },
      "source": [
        "seq_length = X.shape[1]\n",
        "seq_length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rdZSiLFKu5X"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVYSYOUoKzGE"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EQGqJ2MK22_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "91792b7c-880d-411d-b3d4-4bb8ea8a6ee8"
      },
      "source": [
        "model.fit(X, y, batch_size = 256, epochs = 100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "110/110 [==============================] - 59s 503ms/step - loss: 8.1587 - accuracy: 0.0401\n",
            "Epoch 2/100\n",
            "110/110 [==============================] - 54s 494ms/step - loss: 6.9356 - accuracy: 0.0534\n",
            "Epoch 3/100\n",
            "110/110 [==============================] - 54s 491ms/step - loss: 6.8604 - accuracy: 0.0528\n",
            "Epoch 4/100\n",
            "110/110 [==============================] - 54s 491ms/step - loss: 6.7229 - accuracy: 0.0566\n",
            "Epoch 5/100\n",
            "110/110 [==============================] - 55s 496ms/step - loss: 6.5786 - accuracy: 0.0727\n",
            "Epoch 6/100\n",
            "110/110 [==============================] - 54s 495ms/step - loss: 6.4886 - accuracy: 0.0746\n",
            "Epoch 7/100\n",
            "110/110 [==============================] - 54s 492ms/step - loss: 6.3971 - accuracy: 0.0764\n",
            "Epoch 8/100\n",
            "110/110 [==============================] - 55s 498ms/step - loss: 6.2909 - accuracy: 0.0801\n",
            "Epoch 9/100\n",
            "110/110 [==============================] - 55s 496ms/step - loss: 6.2205 - accuracy: 0.0822\n",
            "Epoch 10/100\n",
            "110/110 [==============================] - 53s 486ms/step - loss: 6.1127 - accuracy: 0.0860\n",
            "Epoch 11/100\n",
            "110/110 [==============================] - 53s 483ms/step - loss: 6.0440 - accuracy: 0.0962\n",
            "Epoch 12/100\n",
            "110/110 [==============================] - 55s 496ms/step - loss: 5.9858 - accuracy: 0.1022\n",
            "Epoch 13/100\n",
            "110/110 [==============================] - 54s 488ms/step - loss: 5.9300 - accuracy: 0.1023\n",
            "Epoch 14/100\n",
            "110/110 [==============================] - 54s 495ms/step - loss: 5.9381 - accuracy: 0.0994\n",
            "Epoch 15/100\n",
            "110/110 [==============================] - 53s 486ms/step - loss: 5.9634 - accuracy: 0.0970\n",
            "Epoch 16/100\n",
            "110/110 [==============================] - 53s 485ms/step - loss: 5.8209 - accuracy: 0.1059\n",
            "Epoch 17/100\n",
            "110/110 [==============================] - 54s 489ms/step - loss: 5.7390 - accuracy: 0.1077\n",
            "Epoch 18/100\n",
            "110/110 [==============================] - 54s 493ms/step - loss: 5.6607 - accuracy: 0.1121\n",
            "Epoch 19/100\n",
            "110/110 [==============================] - 54s 494ms/step - loss: 5.5586 - accuracy: 0.1165\n",
            "Epoch 20/100\n",
            "110/110 [==============================] - 53s 484ms/step - loss: 5.5265 - accuracy: 0.1138\n",
            "Epoch 21/100\n",
            "110/110 [==============================] - 55s 497ms/step - loss: 5.4206 - accuracy: 0.1193\n",
            "Epoch 22/100\n",
            "110/110 [==============================] - 53s 482ms/step - loss: 5.3404 - accuracy: 0.1223\n",
            "Epoch 23/100\n",
            "110/110 [==============================] - 54s 490ms/step - loss: 5.2807 - accuracy: 0.1249\n",
            "Epoch 24/100\n",
            "110/110 [==============================] - 55s 497ms/step - loss: 5.2028 - accuracy: 0.1319\n",
            "Epoch 25/100\n",
            "110/110 [==============================] - 54s 495ms/step - loss: 5.1583 - accuracy: 0.1348\n",
            "Epoch 26/100\n",
            "110/110 [==============================] - 52s 475ms/step - loss: 5.0671 - accuracy: 0.1372\n",
            "Epoch 27/100\n",
            "110/110 [==============================] - 53s 477ms/step - loss: 5.0209 - accuracy: 0.1377\n",
            "Epoch 28/100\n",
            "110/110 [==============================] - 54s 495ms/step - loss: 4.9605 - accuracy: 0.1409\n",
            "Epoch 29/100\n",
            "110/110 [==============================] - 56s 507ms/step - loss: 4.8824 - accuracy: 0.1422\n",
            "Epoch 30/100\n",
            "110/110 [==============================] - 55s 500ms/step - loss: 4.7995 - accuracy: 0.1495\n",
            "Epoch 31/100\n",
            "110/110 [==============================] - 56s 505ms/step - loss: 4.7076 - accuracy: 0.1508\n",
            "Epoch 32/100\n",
            "110/110 [==============================] - 55s 498ms/step - loss: 4.6493 - accuracy: 0.1550\n",
            "Epoch 33/100\n",
            "110/110 [==============================] - 55s 504ms/step - loss: 4.5748 - accuracy: 0.1606\n",
            "Epoch 34/100\n",
            "110/110 [==============================] - 54s 488ms/step - loss: 4.5341 - accuracy: 0.1641\n",
            "Epoch 35/100\n",
            "110/110 [==============================] - 53s 480ms/step - loss: 4.6973 - accuracy: 0.1609\n",
            "Epoch 36/100\n",
            "110/110 [==============================] - 53s 483ms/step - loss: 4.5666 - accuracy: 0.1686\n",
            "Epoch 37/100\n",
            "110/110 [==============================] - 53s 484ms/step - loss: 4.4363 - accuracy: 0.1736\n",
            "Epoch 38/100\n",
            "110/110 [==============================] - 54s 487ms/step - loss: 4.4728 - accuracy: 0.1721\n",
            "Epoch 39/100\n",
            "110/110 [==============================] - 54s 488ms/step - loss: 4.5993 - accuracy: 0.1657\n",
            "Epoch 40/100\n",
            "110/110 [==============================] - 55s 498ms/step - loss: 4.4936 - accuracy: 0.1723\n",
            "Epoch 41/100\n",
            "110/110 [==============================] - 53s 483ms/step - loss: 4.4053 - accuracy: 0.1747\n",
            "Epoch 42/100\n",
            "110/110 [==============================] - 55s 501ms/step - loss: 4.3363 - accuracy: 0.1795\n",
            "Epoch 43/100\n",
            "110/110 [==============================] - 55s 503ms/step - loss: 4.2723 - accuracy: 0.1794\n",
            "Epoch 44/100\n",
            "110/110 [==============================] - 56s 511ms/step - loss: 4.1756 - accuracy: 0.1921\n",
            "Epoch 45/100\n",
            "110/110 [==============================] - 55s 497ms/step - loss: 4.1373 - accuracy: 0.1962\n",
            "Epoch 46/100\n",
            "110/110 [==============================] - 55s 504ms/step - loss: 4.1259 - accuracy: 0.1925\n",
            "Epoch 47/100\n",
            "110/110 [==============================] - 54s 487ms/step - loss: 4.0928 - accuracy: 0.1987\n",
            "Epoch 48/100\n",
            "110/110 [==============================] - 54s 494ms/step - loss: 4.1432 - accuracy: 0.2009\n",
            "Epoch 49/100\n",
            "110/110 [==============================] - 54s 488ms/step - loss: 4.0545 - accuracy: 0.1989\n",
            "Epoch 50/100\n",
            "110/110 [==============================] - 55s 501ms/step - loss: 3.9666 - accuracy: 0.2144\n",
            "Epoch 51/100\n",
            "110/110 [==============================] - 53s 486ms/step - loss: 3.8760 - accuracy: 0.2183\n",
            "Epoch 52/100\n",
            "110/110 [==============================] - 53s 482ms/step - loss: 3.8061 - accuracy: 0.2253\n",
            "Epoch 53/100\n",
            " 40/110 [=========>....................] - ETA: 33s - loss: 3.7013 - accuracy: 0.2476"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-924e70a18025>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1_qORQgLD-7"
      },
      "source": [
        "def perplexity2(y_true, y_pred):\n",
        "    time_steps = 50\n",
        "    min_nonzero = np.min(y_pred[np.nonzero(y_pred)])\n",
        "    y_pred[y_pred == 0] = min_nonzero\n",
        "    cross_entropy_over_time = - np.dot(y_true, np.log2(y_pred)) / time_steps\n",
        "    return pow(np.e, cross_entropy_over_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axS4T7_xvp8l"
      },
      "source": [
        "\n",
        "model.save('/content/drive/MyDrive/Classification/model.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-eI6rOs_CQo"
      },
      "source": [
        "from pickle import dump\n",
        "dump(tokenizer, open('/content/drive/MyDrive/Classification/tokenizer.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwVCG0Vpw_-L"
      },
      "source": [
        "from random import randint\n",
        "from pickle import load\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ydWA9d7_Rt2"
      },
      "source": [
        "model1 = load_model('/content/drive/MyDrive/Classification/model.h5')\n",
        " \n",
        "# load the tokenizer\n",
        "tokenizer1 = load(open('/content/drive/MyDrive/Classification/tokenizer.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZKh9SXpySei"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rwtW_DI9FlH",
        "outputId": "9e5b73ef-2be9-419c-863b-b3627b19e030"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR9khN0J9OKW",
        "outputId": "b56dbd2f-69f6-4b75-a23b-62972964ff6d"
      },
      "source": [
        "! pip install \"nltk==3.4.5\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nltk==3.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
            "\r\u001b[K     |▎                               | 10kB 17.4MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 24.7MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 28.6MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 31.3MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 25.8MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61kB 22.7MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71kB 19.8MB/s eta 0:00:01\r\u001b[K     |█▉                              | 81kB 17.1MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 18.5MB/s eta 0:00:01\r\u001b[K     |██▎                             | 102kB 15.8MB/s eta 0:00:01\r\u001b[K     |██▌                             | 112kB 15.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 122kB 15.8MB/s eta 0:00:01\r\u001b[K     |███                             | 133kB 15.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 143kB 15.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 153kB 15.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 163kB 15.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 174kB 15.8MB/s eta 0:00:01\r\u001b[K     |████                            | 184kB 15.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 194kB 15.8MB/s eta 0:00:01\r\u001b[K     |████▌                           | 204kB 15.8MB/s eta 0:00:01\r\u001b[K     |████▊                           | 215kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 225kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 235kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 245kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 256kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 266kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 276kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 286kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 296kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 307kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 317kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 327kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 337kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 348kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 358kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 368kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 378kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 389kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 399kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 409kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 419kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 430kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 440kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 450kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 460kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 471kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 481kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 491kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 501kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 512kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 522kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 532kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 542kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 552kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 563kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 573kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 583kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 593kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 604kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 614kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 624kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 634kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 645kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 655kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 665kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 675kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 686kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 696kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 706kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 716kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 727kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 737kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 747kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 757kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 768kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 778kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 788kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 798kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 808kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 819kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 829kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 839kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 849kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 860kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 870kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 880kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 890kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 901kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 911kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 921kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 931kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 942kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 952kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 962kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 972kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 983kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 993kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.0MB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.0MB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.0MB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.0MB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.0MB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.1MB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.1MB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.1MB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.1MB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.1MB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.1MB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.1MB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.1MB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.2MB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2MB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.2MB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.2MB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.2MB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.2MB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2MB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2MB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.3MB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3MB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.3MB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.3MB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.3MB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3MB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.3MB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.3MB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.3MB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.4MB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4MB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.4MB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.4MB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.4MB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4MB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.4MB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.4MB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.4MB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.4MB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 15.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4.5) (1.15.0)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-cp37-none-any.whl size=1449909 sha256=488b11fc765f9894635711c7565802e6b3034f23bc0d5ca69e64fbd25748f423\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
            "Successfully built nltk\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPUlGoT19gTS"
      },
      "source": [
        "def generate_text_seq(model, tokenizer, text_seq_length, seed_text, n_words):\n",
        "  text = []\n",
        "\n",
        "  for _ in range(n_words):\n",
        "    encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen = text_seq_length, truncating='pre')\n",
        "\n",
        "    y_predict = model.predict_classes(encoded)\n",
        "\n",
        "    predicted_word = ''\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == y_predict:\n",
        "        predicted_word = word\n",
        "        break\n",
        "    seed_text = seed_text + ' ' + predicted_word\n",
        "    text.append(predicted_word)\n",
        "  return ' '.join(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1yu5HeLBaKD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "PilxG-lNGmkP",
        "outputId": "4e758593-0a05-423d-bcb8-da2fec715644"
      },
      "source": [
        "\n",
        "seed_text=lines[2]\n",
        "seed_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'drawback of इस योजना is that इस सब्सिडी is not एक बड़ी खामी up with महंगाई दर दिल्ली is an urban territory there banks are in बैंक बहुतायत and most of अधिकांश लोगों पास also have bank accounts यही बात can also be said about आधार कार्ड भी but various complaints'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "-aXS2zzrGnZQ",
        "outputId": "90448290-97c7-41d9-95cb-5dab94c87019"
      },
      "source": [
        "generate_text_seq(model, tokenizer, seq_length, seed_text, 100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'are found in the requirement of कृषि उत्पादों is why तेल is the colorless and second roughly गाँवों is fungicide there is being propose and राज्य roughly गाँवों in rural areas of कृषि and short fibers in the form of वाष्प is been done in the form of अनुमानित varieties of the sowing in the leaves of the बंगाल in सॉफ़्टवेयर बंगाल in 25 20 लाख टन in भारत and पहली बेसिन and rural mills in the form of विश्\\u200dव हर्बल अनुसंधान संस्थान and also छत of the form of कृषि उत्पादों is compared to the form of the form'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Rl9SRsUGzY4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}